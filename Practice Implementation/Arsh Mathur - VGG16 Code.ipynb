{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(Module):\n",
    "    def __init__(self, input_channels,classes):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        self.conv1 = Conv2d(input_channels,64,3,1,1)\n",
    "        self.conv2 = Conv2d(64,64,3,1,1)\n",
    "        self.pool1 = MaxPool2d(2,2)\n",
    "\n",
    "        self.conv3 = Conv2d(64,128,3,1,1)\n",
    "        self.conv4 = Conv2d(128,128,3,1,1)\n",
    "        self.pool2 = MaxPool2d(2,2)\n",
    "\n",
    "        self.conv5 = Conv2d(128,256,3,1,1)\n",
    "        self.conv6 = Conv2d(256,256,3,1,1)\n",
    "        self.pool3 = MaxPool2d(2,2)\n",
    "\n",
    "        self.conv7 = Conv2d(256,512,3,1,1)\n",
    "        self.conv8 = Conv2d(512,512,3,1,1)\n",
    "        self.pool4 = MaxPool2d(2,2)\n",
    "\n",
    "        self.conv9 = Conv2d(512,512,3,1,1)\n",
    "        self.conv10 = Conv2d(512,512,3,1,1)\n",
    "        self.pool5 = MaxPool2d(2,2)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1)\n",
    "        self.fc1 = Linear(512*7*7,4096)\n",
    "        self.fc2 = Linear(4096,4096)\n",
    "        self.fc3 = Linear(4096,classes)    \n",
    "\n",
    "        self.relu = ReLU()\n",
    "        self.logsoftmax = LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu(self.conv7(x))\n",
    "        x = self.relu(self.conv8(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu(self.conv9(x))\n",
    "        x = self.relu(self.conv10(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        print('dimensions of x before passing in fully connected layers', np.shape(x))\n",
    "\n",
    "     \n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return self.logsoftmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of x before passing in fully connected layers torch.Size([1, 512, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3060, -2.3073, -2.2922, -2.3110, -2.3107, -2.3073, -2.2857, -2.2972,\n",
       "         -2.3009, -2.3078]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the output dimensions\n",
    "\n",
    "model1 = VGG(3, 10) # 3 channels for RGB images\n",
    "model1 = model1.to(device)\n",
    "model1.forward(torch.rand(1,3,224,224).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import KMNIST\n",
    "from torchvision.datasets import Kitti\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "\n",
    "trainData = Kitti(root = 'data', train=True, download = True, transform = ToTensor())\n",
    "testData = Kitti(root = 'data', train=False, download = True, transform = ToTensor())\n",
    "\n",
    "numTrainSamples = int(TRAIN_SPLIT * len(trainData)) \n",
    "numValSamples = int(VAL_SPLIT * len(trainData))\n",
    "\n",
    "(trainData, valData) = random_split(trainData,\n",
    "\t[numTrainSamples, numValSamples],\n",
    "\tgenerator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainData, batch_size = BATCH_SIZE, shuffle = True)\n",
    "valDataLoader = DataLoader(valData, batch_size = BATCH_SIZE)\n",
    "testDataLoader = DataLoader(testData, batch_size = BATCH_SIZE)\n",
    "\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE\n",
    "\n",
    "model = VGG(3, classes=len(trainData.dataset.classes).to(device)) # 3 channels for RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.NLLLoss()\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to understand this part of the code\n",
    "#training mode\n",
    "for e in range(0, EPOCHS):\n",
    "\tmodel.train()\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalValLoss = 0\n",
    "\ttrainCorrect = 0\n",
    "\tvalCorrect = 0\n",
    "\tfor (x, y) in trainDataLoader:\n",
    "\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\tpred = model(x)\n",
    "\t\tloss = lossFn(pred, y)\n",
    "\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\t\t\n",
    "\t\ttotalTrainLoss += loss\n",
    "\t\ttrainCorrect += (pred.argmax(1) == y).type(\n",
    "\t\t\ttorch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
